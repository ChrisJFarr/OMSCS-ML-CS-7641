Decision tree

## Preprocessing
* no preprocessing was utilized for all of the decision tree experiments. This is because 
I believe that decision trees are fairly robust to irregular scales and distributions since
the decision function only depends on a point within the disribution of the feature.
    

validation curve parameters for experiments 1, 2 and 3
max_depth:
    start: 2
    stop: 10
    step: 1
ccp_alpha:
    start: 0.0
    stop: 0.051
    step: 0.001
min_samples_split:
    start: 2
    stop: 500
    step: 25
min_samples_leaf:
    start: 1
    stop: 500
    step: 25

###########
Problem 1
###########

## Perform Validation Curve analysis

Validation curve completed in 34.3 seconds


* Starting from default parameters, performed validation curve analysis on the following parameters:
    * Top performance is test AUC=.81
        * achieved with all defaults and setting min_samples_leaf to 26
            * train AUC .879 test AUC=.812
        * achieved with all defaults and setting min_samples_split to 102
            * train AUC .862 test AUC=.810 (slightly less overfitting) 
    * max-depth
        * train .854 and test .793 with max-depth=3
        * this reduced overfitting at cost of some performance compared to top metrics
    * ccp_alpha
        * train .848 and test .794 with ccp_alpha=0.01
        * similar effect of max-depth on test performance (when viewing the curve) but inverse
            impact on the training


Additionally I compared the performance of gini vs entropy for the validation curves.
The performance was very similar although in some cases entropy had a test auc about .002
higher than gini. The runtime was also slightly longer, as i expected based on some research
about runtimes comparing the two (https://quantdare.com/decision-trees-gini-vs-entropy/)
I decided to stick with gini to have consistent default parameters throughout the three tree
experiments since the ds2 is significantly larger than ds1 and this could hurt the runtime for
the experiments.

## Grid-Search

grid-search parameters
* Performed grid-search cv from defaults and through max-performing values discovered above


Round 1
Performing grid search...
Grid-Search Parameters:
{'model__ccp_alpha': [0.0, 0.005, 0.01, 0.015],
 'model__min_samples_leaf': [15, 20, 25, 30, 35, 40, 45]}
Fitting on 614 train examples...
Best parameters
{'model__ccp_alpha': 0.0, 'model__min_samples_leaf': 30}
'Best performance: 0.811'
Grid search completed in 5.9 seconds


## Learning Curve

With the best model parameters, compute the learning curve.
Learning curve completed in 7.1 seconds
* Analysis: Clearly there is a trend which shows in general more data leads to higher performance. A dataset
    several times the one used would likely produce better results. Performance further improves when using 94%
    of the data, likely indicating there are a few harder examples that happen to get removed until more  than 94%
    of the data is used at the random seed used.

Performing full test evaluation...
Training time: 0.002
Inference time: 0.000
Final Performance Evaluation:
{'test_auc': 0.7884259259259259, 'train_auc': 0.8797371495327103}

###############
Problem 2
#############

# Grid search

Round 1
Performing grid search...
Grid-Search Parameters:
{'model__ccp_alpha': [0.0, 0.005, 0.01, 0.015, 0.02],
 'model__min_samples_split': [2, 102, 202, 302, 402]}
Fitting on 202944 train examples...
Best parameters
{'model__ccp_alpha': 0.0, 'model__min_samples_split': 402}
'Best performance: 0.809'
Grid search completed in 18.7 seconds
Round 2
Performing grid search...
Grid-Search Parameters:
{'model__ccp_alpha': [0.0, 0.005, 0.01, 0.015, 0.02],
 'model__min_samples_split': [400, 500, 600, 700, 800]}
Fitting on 202944 train examples...
Best parameters
{'model__ccp_alpha': 0.0, 'model__min_samples_split': 800}
'Best performance: 0.813'
Grid search completed in 11.0 seconds
Round 3
Performing grid search...
Grid-Search Parameters:
{'model__ccp_alpha': [0.0, 0.005, 0.01, 0.015, 0.02],
 'model__min_samples_split': [800, 1050, 1300, 1550, 1800]}
Fitting on 202944 train examples...
Best parameters
{'model__ccp_alpha': 0.0, 'model__min_samples_split': 1050}
'Best performance: 0.813'
Grid search completed in 10.3 seconds


Generating learning curve...
Learning curve completed in 90.2 seconds

Performing full test evaluation...
Training time: 0.372
Inference time: 0.006
Final Performance Evaluation:
{'test_auc': 0.8093300530491416, 'train_auc': 0.8258133499942515}